{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "CapsuleNet - Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2EbHEUahqZ8",
        "colab_type": "text"
      },
      "source": [
        "# Baseline\n",
        "We trained a simple, one layer RNN featuring LSTM units and a pretrained word embedding layer. The model was trained on 5 epochs and had the following metrics:\n",
        "\n",
        "**Train average AUROC:** 0.984\n",
        "\n",
        "**Validation average AUROC:** 0.98\n",
        "\n",
        "**Test average AUROC:** 0.968"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL20laEKhqaG",
        "colab_type": "code",
        "outputId": "d0ea70b1-dede-458d-d65a-ddf8d4a96c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# tf-related\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHHCyv11h9oH",
        "colab_type": "code",
        "outputId": "45efb3e3-4169-48a1-cbcf-cef75469dd39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9npSGfqqhqaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# execution hyperparameters\n",
        "MAX_WORDS = 100000\n",
        "VALIDATION_SPLIT = .2\n",
        "EMBEDDING_DIM = 100\n",
        "embedding_dim = 100\n",
        "max_length = 16\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size=160000\n",
        "test_portion=.1\n",
        "corpus = []\n",
        "DATA_PATH = 'gdrive/My Drive/Toxic Comments/data/'\n",
        "glove_path = DATA_PATH + \"glove.6B/glove.6B.100d.txt\" # file name specifies dimension of embedding space\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMXir1D0hqal",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization and sequence formation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StdgAZGfhqao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# obtain training 'labels' and 'sentences'\n",
        "train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
        "labels = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values.tolist()\n",
        "labels = np.array(labels)\n",
        "sentences = train[\"comment_text\"].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5LwXNHNhqav",
        "colab_type": "code",
        "outputId": "1961386c-dff8-4689-c0b2-32bf7090730d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# word tokenization\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(\"Words in training set: \"+str(len(word_index)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words in training set: 210337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2jm47-2hqa5",
        "colab_type": "text"
      },
      "source": [
        "We observe that the training set actually has many more unique tokens than the number of words we will admit for computational reasons. This calls for further investigation. Let's look at the sentences' length distribution to decide on a reasonable maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4TGlD_RhqbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cutting around the 90th percentile seems reasonable given the distribution's long tail\n",
        "MAX_SEQ_LENGTH = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_2WG6xxhqbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make the sequences uniform to pass them to a network\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVMO--u3hqbc",
        "colab_type": "text"
      },
      "source": [
        "## Data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvXDYJyWhqbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the data into a training set and a validation set\n",
        "indices = np.arange(padded.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "padded = padded[indices]\n",
        "labels = labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * padded.shape[0])\n",
        "\n",
        "x_train = padded[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = padded[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r0dYL6Lhqbk",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning\n",
        "We followed [this tutorial from the Keras documentation](https://keras.io/examples/pretrained_word_embeddings/) to implement transfer learning of a pretrained GloVe embedding. The training data for the embedding consists of messages from a forum-like network termed 'netnews'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGIvsUYehqbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pretrained embedding matrix (implemented as an index for memory efficiency)\n",
        "embeddings_index = {}\n",
        "with open(glove_path) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p2pUw9Ghqbr",
        "colab_type": "code",
        "outputId": "62f6d2a3-7de8-4cca-893a-0b4a26177606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# prepare embedding matrix\n",
        "num_words = min(MAX_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQ_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0719 18:50:41.314832 140670169905024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50yIOIzfhqbw",
        "colab_type": "text"
      },
      "source": [
        "## RNN training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNbJGBfBhqbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras-ready average AUROC\n",
        "from avg_auroc import AvgAurocCallback, avg_auroc_metric\n",
        "avg_auroc_callback = AvgAurocCallback(x_train, y_train, x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oC-MsGYjMBU",
        "colab_type": "code",
        "outputId": "9a508ff3-95cf-4415-fa4c-4fa872fca683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-6pggm_2_\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-6pggm_2_\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dsbzoc8p/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViledNhHjibN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_contrib.layers.capsule import Capsule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpxhPJVYhqb2",
        "colab_type": "code",
        "outputId": "602c65fd-32aa-4bba-aea9-ac70c2475d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "    embedding_layer,\n",
        "    keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(128, activation='relu', dropout=0.25, \n",
        "                         recurrent_dropout=0.25, return_sequences=True)),\n",
        "    Capsule(num_capsule=10, dim_capsule=16, routings=5, \n",
        "            activation='sigmoid', share_weights=True),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(rate=0.25),\n",
        "    keras.layers.Dense(6, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 18:50:50.237428 140670169905024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0719 18:50:50.444626 140670169905024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0719 18:50:50.606158 140670169905024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0719 18:50:50.622828 140670169905024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0_d2mDdnsoz",
        "colab_type": "code",
        "outputId": "268c5d23-831c-4fa3-d7cd-9c738e0d482b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 18:50:51.726307 140670169905024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0719 18:50:51.760720 140670169905024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0719 18:50:51.767787 140670169905024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 100)          10000100  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 150, 256)          175872    \n",
            "_________________________________________________________________\n",
            "capsule_1 (Capsule)          (None, 10, 16)            40960     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 966       \n",
            "=================================================================\n",
            "Total params: 10,217,898\n",
            "Trainable params: 217,798\n",
            "Non-trainable params: 10,000,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_ZtQuDihqb9",
        "colab_type": "code",
        "outputId": "6f0a0d92-7316-4a52-945c-c24cc33e3e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 150, 100)          10000100  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 150, 256)          175872    \n",
            "_________________________________________________________________\n",
            "capsule_1 (Capsule)          (None, 10, 16)            40960     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 966       \n",
            "=================================================================\n",
            "Total params: 10,217,898\n",
            "Trainable params: 217,798\n",
            "Non-trainable params: 10,000,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cGyLHtHkhqcG",
        "colab_type": "code",
        "outputId": "bb2376c7-390f-4c1f-8db3-743a81acfed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "num_epochs = 6\n",
        "history = model.fit(x_train, y_train, epochs=num_epochs, verbose=1, batch_size=128, validation_data=(x_val, y_val),\n",
        "                   callbacks=[avg_auroc_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 127657 samples, validate on 31914 samples\n",
            "Epoch 1/6\n",
            "127657/127657 [==============================] - 545s 4ms/step - loss: 0.0769 - val_loss: 0.0546\n",
            "\n",
            "Train avg_auroc: 0.970, Val avg_auroc: 0.969\n",
            "Epoch 2/6\n",
            "127657/127657 [==============================] - 542s 4ms/step - loss: 0.0561 - val_loss: 0.0497\n",
            "\n",
            "Train avg_auroc: 0.979, Val avg_auroc: 0.977\n",
            "Epoch 3/6\n",
            "127657/127657 [==============================] - 529s 4ms/step - loss: 0.0526 - val_loss: 0.0475\n",
            "\n",
            "Train avg_auroc: 0.982, Val avg_auroc: 0.979\n",
            "Epoch 4/6\n",
            "127657/127657 [==============================] - 516s 4ms/step - loss: 0.0501 - val_loss: 0.0471\n",
            "\n",
            "Train avg_auroc: 0.983, Val avg_auroc: 0.981\n",
            "Epoch 5/6\n",
            "127657/127657 [==============================] - 510s 4ms/step - loss: 0.0483 - val_loss: 0.0453\n",
            "\n",
            "Train avg_auroc: 0.986, Val avg_auroc: 0.983\n",
            "Epoch 6/6\n",
            "127657/127657 [==============================] - 502s 4ms/step - loss: 0.0466 - val_loss: 0.0450\n",
            "\n",
            "Train avg_auroc: 0.987, Val avg_auroc: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Tqs0oXht6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history['roc_train'] = avg_auroc_callback.roc_train\n",
        "history.history['roc_val'] = avg_auroc_callback.roc_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpIXl7rchqcN",
        "colab_type": "text"
      },
      "source": [
        "## Make a submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo8wG8OShqcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(DATA_PATH + \"test.csv\")\n",
        "test_sentences = test.pop(\"comment_text\").values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBUB62bNhqcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make the sequences uniform to pass them to a network\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQ_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwX9pB6yhqcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions\n",
        "y_test_hat = model.predict(test_padded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9esIuMX1hqce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write submission file\n",
        "y_test_hat = pd.DataFrame(data=y_test_hat, columns=[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
        "test = test.join(y_test_hat)\n",
        "test.to_csv(\"tuned_capsule_biderectional_gru_submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91BYwsvJhqch",
        "colab_type": "text"
      },
      "source": [
        "## Store results\n",
        "We'll store the final `History` object to make graphs and the model weights to further train this model, as the small difference between training and validation performance tells us it hasn't reached its full potential."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mqCJrVUhqcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZobnnxCRhqco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_file = open(\"tuned_capsule_b-gru_history\", \"wb\")\n",
        "pickle.dump(history.history, hist_file)\n",
        "hist_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaH0tWotVXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}